{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae3244a",
   "metadata": {},
   "source": [
    "## 4. Relu & Flatten\n",
    "- 은닉층의 활성화 함수로 시그모이드 함수를 쓰게 된다면 양쪽 끝의 그래프가 완만하기 때문에 올바른 출력을 만드는데 대응이 느리다.\n",
    "- 특히 층이 많을 수록 그 효과가 누적되어 학습이 어려워진다.\n",
    "#### Relu\n",
    "- 이러한 단점을 극복하기 위해 렐루라는 활성화 함수가 등장하였다.\n",
    "- 입력이 양수일 경우 그대로 통과시키고, 음수의 경우 0으로 만드는 함수이다.\n",
    "#### Flatten\n",
    "- 배치 차원을 제외한 나머지 입력 차원을 모두 일렬로 펼치는 함수로, 입력에 곱해지는 가중치나 절편이 없다.\n",
    "- Flatten 층은 입력층 바로 뒤에 추가해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e347ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad418e",
   "metadata": {},
   "source": [
    "- flatten 클래스의 모델 파라미터는 0개이다.\n",
    "- flatten 층을 모델에 추가하면, 앞서 모델들에서 볼 수 없던 입력값의 차원을 확인 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8493d5",
   "metadata": {},
   "source": [
    "### 4-1. 모델 재훈련\n",
    "- 재정의한 모델을 reshape 하기 전의 데이터에 적용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b04e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 1s 870us/step - loss: 0.5372 - accuracy: 0.8101\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.3931 - accuracy: 0.8597\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 1s 859us/step - loss: 0.3548 - accuracy: 0.8722\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 1s 856us/step - loss: 0.3315 - accuracy: 0.8820\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 1s 855us/step - loss: 0.3201 - accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feeed7d8130>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 로드\n",
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 2. 표준화 전처리\n",
    "train_scaled = train_input / 255.0\n",
    "\n",
    "# 3. 검증세트 분리\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled, train_target, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# 4. 모델 훈련 전 설정\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "# 5. 모델 훈련\n",
    "model.fit(train_scaled, train_target, epochs = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce602c",
   "metadata": {},
   "source": [
    "### 4-2. 모델 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba2a4b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 0s 559us/step - loss: 0.3649 - accuracy: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36486828327178955, 0.8769999742507935]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8a022",
   "metadata": {},
   "source": [
    "- **훈련 세트와 테스트 세트의 정확도가 이전 모델에 비하면 다 높아졌다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a5725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
